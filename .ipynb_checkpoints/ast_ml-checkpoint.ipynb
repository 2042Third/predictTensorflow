{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0076c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# example of making a single class prediction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d68f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ast data\n",
    "c_names=[\"org\",\"Dyn\",\"Func\",\"Dec\",\"With\",\"Asc\",\"Relatedness\"]\n",
    "ad = pd.read_csv('new.csv', names=c_names, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af016675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                org   Dyn  Func   Dec  With  Asc  Relatedness\n",
      "0      000Justin000     0     0     0     1    0            1\n",
      "1                11     1     0     1     0    0            0\n",
      "2            007gzs   115    40    53     6    0            1\n",
      "3        00riddle00     0     1     0     0    0            1\n",
      "4       1.11001E+14   654  1133   456   247    0            1\n",
      "...             ...   ...   ...   ...   ...  ...          ...\n",
      "32695      zzy93421     2     7     0     0    0            0\n",
      "32696        zzzeek  1011  3113  2854  2040   52            1\n",
      "32697      zzzombat     4     4    15     5    0            1\n",
      "32698      zzzzRuby     1     0     0    15    0            0\n",
      "32699       zzzzzsh    40    66   122    32    0            1\n",
      "\n",
      "[32700 rows x 7 columns]\n",
      "0           0\n",
      "1           1\n",
      "2          53\n",
      "3           0\n",
      "4         456\n",
      "         ... \n",
      "32695       0\n",
      "32696    2854\n",
      "32697      15\n",
      "32698       0\n",
      "32699     122\n",
      "Name: Dec, Length: 32700, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ad)\n",
    "print(ad['Dec'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f8e32",
   "metadata": {},
   "source": [
    "## Decorators and Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418e9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainxor = ad[['Dec', \"Func\"]]\n",
    "trainyor = ad[['Relatedness']]\n",
    "# trainx = ad[['Dyn']]\n",
    "# trainy = ad[[ \"Func\", 'DynFunc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f5ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    trainxor, trainyor, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d9db5",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbc6090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77049558 0.7705121  0.77101461 0.77159131 0.77332143 0.77505154\n",
      " 0.77620495]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.BayesianRidge()\n",
    "dn, fc = 0, 3\n",
    "model = reg.fit(X_train, y_train.values.ravel())\n",
    "xnew = [[0,1],[1,0],[0,10],[0,20],[0,50],[0,80],[0,100]]\n",
    "y_pred = model.predict(xnew)\n",
    "print(y_pred)\n",
    "# print(classification_report(y_test,y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(\"Precision score: {}\".format(precision_score(y_test,y_pred)))\n",
    "# xprobs = model.predict_proba(X_test)\n",
    "# for i in range(len(xnew)):\n",
    "# \tprint(\"X=%s, Predicted=%s\" % (xnew[i], [round(xprobs[i][0],3),round(xprobs[i][1],3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09617f",
   "metadata": {},
   "source": [
    "### Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bced5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.99      0.43       749\n",
      "           1       0.98      0.23      0.37      2521\n",
      "\n",
      "    accuracy                           0.40      3270\n",
      "   macro avg       0.63      0.61      0.40      3270\n",
      "weighted avg       0.82      0.40      0.38      3270\n",
      "\n",
      "[[ 740    9]\n",
      " [1951  570]]\n",
      "Precision score: 0.9844559585492227\n",
      "X=[0, 1], Predicted=[0.994, 0.006]\n",
      "X=[1, 0], Predicted=[0.064, 0.936]\n",
      "X=[0, 10], Predicted=[0.994, 0.006]\n",
      "X=[0, 20], Predicted=[0.0, 1.0]\n",
      "X=[0, 50], Predicted=[0.994, 0.006]\n",
      "X=[0, 80], Predicted=[0.994, 0.006]\n",
      "X=[0, 100], Predicted=[0.867, 0.133]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gnb = GaussianNB()\n",
    "dn, fc = 0, 3\n",
    "model = gnb.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Precision score: {}\".format(precision_score(y_test,y_pred)))\n",
    "xnew = [[0,1],[1,0],[0,10],[0,20],[0,50],[0,80],[0,100]]\n",
    "xprobs = model.predict_proba(X_test)\n",
    "for i in range(len(xnew)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (xnew[i], [round(xprobs[i][0],3),round(xprobs[i][1],3)]))\n",
    "# while True:\n",
    "#   dn, fc = [int(x) for x in input(\"Next prediction\\n\").split(',')]\n",
    "#   y_pred = model.predict([[dn, fc]])\n",
    "#   print(\"Predict [%d, %d] %d\" % (dn, fc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbce3b9",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d7c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       749\n",
      "           1       0.77      1.00      0.87      2521\n",
      "\n",
      "    accuracy                           0.77      3270\n",
      "   macro avg       0.39      0.50      0.44      3270\n",
      "weighted avg       0.59      0.77      0.67      3270\n",
      "\n",
      "[[   0  749]\n",
      " [   0 2521]]\n",
      "Precision score: 0.7709480122324159\n",
      "X=[0, 1], Predicted=[0.313, 0.687]\n",
      "X=[1, 0], Predicted=[0.017, 0.983]\n",
      "X=[0, 10], Predicted=[0.305, 0.695]\n",
      "X=[0, 20], Predicted=[0.0, 1.0]\n",
      "X=[0, 50], Predicted=[0.313, 0.687]\n",
      "X=[0, 80], Predicted=[0.282, 0.718]\n",
      "X=[0, 100], Predicted=[0.051, 0.949]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18604\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\18604\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\18604\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "dn, fc = 0, 3\n",
    "model = logreg.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Precision score: {}\".format(precision_score(y_test,y_pred)))\n",
    "xnew = [[0,1],[1,0],[0,10],[0,20],[0,50],[0,80],[0,100]]\n",
    "xprobs = model.predict_proba(X_test)\n",
    "for i in range(len(xnew)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (xnew[i], [round(xprobs[i][0],3),round(xprobs[i][1],3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4fd1d",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea1326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainxor = ad[['With','Dec']]\n",
    "trainyor = ad[['Relatedness']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    trainxor, trainyor, test_size=0.1, random_state=0)\n",
    "\n",
    "mlpc=MLPClassifier(hidden_layer_sizes=(11,11,11),max_iter=500)\n",
    "model = mlpc.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205c509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.17      0.26       749\n",
      "           1       0.80      0.96      0.87      2521\n",
      "\n",
      "    accuracy                           0.78      3270\n",
      "   macro avg       0.69      0.57      0.57      3270\n",
      "weighted avg       0.75      0.78      0.73      3270\n",
      "\n",
      "[[ 128  621]\n",
      " [  94 2427]]\n",
      "Precision score: 0.7962598425196851\n",
      "X=[0, 1], Predicted=[0.406, 0.594]\n",
      "X=[1, 0], Predicted=[0.011, 0.989]\n",
      "X=[0, 10], Predicted=[0.22, 0.78]\n",
      "X=[0, 20], Predicted=[0.0, 1.0]\n",
      "X=[0, 50], Predicted=[0.406, 0.594]\n",
      "X=[0, 80], Predicted=[0.094, 0.906]\n",
      "X=[0, 100], Predicted=[0.199, 0.801]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Precision score: {}\".format(precision_score(y_test,y_pred)))\n",
    "xnew = [[0,1],[1,0],[0,10],[0,20],[0,50],[0,80],[0,100]]\n",
    "xprobs = model.predict_proba(X_test)\n",
    "for i in range(len(xnew)):\n",
    "\tprint(\"X=%s, Predicted=%s\" % (xnew[i], [round(xprobs[i][0],3),round(xprobs[i][1],3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94baecb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
